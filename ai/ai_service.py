"""
AIæœåŠ¡ç®¡ç†å™¨

ç»Ÿä¸€ç®¡ç†AIåˆ†æåŠŸèƒ½ï¼Œæ”¯æŒå¤šç§AIåç«¯ï¼ˆOllamaã€OpenAIç­‰ï¼‰
æä¾›å¯¹è¯æ‘˜è¦ã€æ ‡ç­¾æå–ã€è‡ªåŠ¨åˆ†ç±»ç­‰åŠŸèƒ½ã€‚

ä½œè€…: ChatCompass Team
ç‰ˆæœ¬: v1.2.2
"""

import os
import logging
from typing import Optional, List, Dict, Any
from dataclasses import dataclass, asdict
from .ollama_client import OllamaClient, AIAnalysisResult

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class AIConfig:
    """AIæœåŠ¡é…ç½®"""
    enabled: bool = True
    backend: str = "ollama"  # ollama, openai, deepseek
    ollama_host: str = "http://localhost:11434"
    ollama_model: str = "qwen2.5:3b"
    timeout: int = 180  # å¢åŠ åˆ°180ç§’å¤„ç†å¤§æ–‡æœ¬
    auto_analyze: bool = False  # æ˜¯å¦è‡ªåŠ¨åˆ†ææ–°å¯¹è¯
    enable_fallback: bool = True  # è¶…æ—¶æ—¶æ˜¯å¦å¯ç”¨é™çº§æ–¹æ¡ˆ
    
    @classmethod
    def from_env(cls) -> 'AIConfig':
        """ä»ç¯å¢ƒå˜é‡åˆ›å»ºé…ç½®"""
        return cls(
            enabled=os.getenv('AI_ENABLED', 'true').lower() == 'true',
            backend=os.getenv('AI_BACKEND', 'ollama'),
            ollama_host=os.getenv('OLLAMA_HOST', 'http://localhost:11434'),
            ollama_model=os.getenv('OLLAMA_MODEL', 'qwen2.5:3b'),
            timeout=int(os.getenv('AI_TIMEOUT', '180')),  # é»˜è®¤180ç§’
            auto_analyze=os.getenv('AI_AUTO_ANALYZE', 'false').lower() == 'true',
            enable_fallback=os.getenv('AI_ENABLE_FALLBACK', 'true').lower() == 'true'
        )


class AIService:
    """AIæœåŠ¡ç®¡ç†å™¨"""
    
    def __init__(self, config: Optional[AIConfig] = None):
        """
        åˆå§‹åŒ–AIæœåŠ¡
        
        Args:
            config: AIé…ç½®å¯¹è±¡ï¼Œå¦‚æœä¸ºNoneåˆ™ä»ç¯å¢ƒå˜é‡è¯»å–
        """
        self.config = config or AIConfig.from_env()
        self.client = None
        
        if self.config.enabled:
            self._initialize_client()
    
    def _initialize_client(self):
        """åˆå§‹åŒ–AIå®¢æˆ·ç«¯"""
        try:
            if self.config.backend == 'ollama':
                self.client = OllamaClient(
                    base_url=self.config.ollama_host,
                    model=self.config.ollama_model,
                    timeout=self.config.timeout
                )
                logger.info(f"âœ… Ollamaå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ: {self.config.ollama_model}")
            
            elif self.config.backend == 'openai':
                from .openai_client import OpenAIClient
                self.client = OpenAIClient()
                logger.info("âœ… OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            
            elif self.config.backend == 'deepseek':
                from .openai_client import DeepSeekClient
                self.client = DeepSeekClient()
                logger.info("âœ… DeepSeekå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„AIåç«¯: {self.config.backend}")
        
        except Exception as e:
            logger.error(f"âŒ AIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            self.config.enabled = False
    
    def is_available(self) -> bool:
        """æ£€æŸ¥AIæœåŠ¡æ˜¯å¦å¯ç”¨"""
        if not self.config.enabled or not self.client:
            return False
        
        try:
            if isinstance(self.client, OllamaClient):
                return self.client.is_available()
            else:
                # å…¶ä»–å®¢æˆ·ç«¯çš„æ£€æŸ¥é€»è¾‘
                return True
        except:
            return False
    
    def get_status(self) -> Dict[str, Any]:
        """è·å–AIæœåŠ¡çŠ¶æ€"""
        status = {
            'enabled': self.config.enabled,
            'backend': self.config.backend,
            'available': False,
            'model': None,
            'available_models': []
        }
        
        if not self.config.enabled:
            status['message'] = 'AIåŠŸèƒ½æœªå¯ç”¨'
            return status
        
        if not self.client:
            status['message'] = 'AIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–'
            return status
        
        try:
            status['available'] = self.is_available()
            
            if isinstance(self.client, OllamaClient):
                status['model'] = self.client.model
                if status['available']:
                    status['available_models'] = self.client.list_models()
            
            status['message'] = 'AIæœåŠ¡æ­£å¸¸' if status['available'] else 'AIæœåŠ¡ä¸å¯ç”¨'
        
        except Exception as e:
            status['message'] = f'çŠ¶æ€æ£€æŸ¥å¤±è´¥: {str(e)}'
        
        return status
    
    def analyze_conversation(self, 
                            conversation_text: str,
                            title: str = "",
                            show_progress: bool = True) -> Optional[AIAnalysisResult]:
        """
        åˆ†æå¯¹è¯å†…å®¹
        
        Args:
            conversation_text: å¯¹è¯æ–‡æœ¬
            title: å¯¹è¯æ ‡é¢˜ï¼ˆå¯é€‰ï¼‰
            show_progress: æ˜¯å¦æ˜¾ç¤ºå¤„ç†è¿›åº¦ï¼ˆæ¨èå¤§æ–‡æœ¬æ—¶å¼€å¯ï¼‰
        
        Returns:
            AIAnalysisResultå¯¹è±¡ï¼Œå¤±è´¥è¿”å›None
        """
        if not self.config.enabled:
            logger.warning("AIåŠŸèƒ½æœªå¯ç”¨")
            return None
        
        if not self.is_available():
            logger.warning("AIæœåŠ¡ä¸å¯ç”¨")
            return None
        
        try:
            text_length = len(conversation_text)
            title_info = f': {title}' if title else ''
            
            logger.info(f"ğŸš€ å¼€å§‹åˆ†æå¯¹è¯{title_info}ï¼ˆ{text_length:,} å­—ç¬¦ï¼‰")
            
            # å¤§æ–‡æœ¬æç¤º
            if text_length > 10000:
                logger.info(f"ğŸ’¡ æ£€æµ‹åˆ°å¤§æ–‡æœ¬ï¼Œé¢„è®¡å¤„ç†æ—¶é—´: {text_length//1000 * 2}-{text_length//1000 * 5}ç§’")
            
            # è°ƒç”¨AIåˆ†æ
            result = self.client.analyze_conversation(conversation_text)
            
            logger.info(f"âœ… åˆ†æå®Œæˆ: {result.category} | ç½®ä¿¡åº¦: {result.confidence}")
            logger.info(f"   ğŸ“ æ‘˜è¦: {result.summary[:80]}{'...' if len(result.summary) > 80 else ''}")
            logger.info(f"   ğŸ·ï¸  æ ‡ç­¾: {', '.join(result.tags)}")
            
            return result
        
        except TimeoutError as e:
            logger.error(f"âŒ åˆ†æè¶…æ—¶: {e}")
            logger.error(f"ğŸ’¡ å»ºè®®: 1) å¢åŠ AI_TIMEOUTç¯å¢ƒå˜é‡ 2) ä½¿ç”¨åˆ†æ®µå¤„ç† 3) åˆ‡æ¢åˆ°æ›´å¿«çš„æ¨¡å‹")
            
            # é™çº§æ–¹æ¡ˆï¼šç”ŸæˆåŸºç¡€æ‘˜è¦
            if self.config.enable_fallback:
                logger.info("ğŸ”„ å¯åŠ¨é™çº§æ–¹æ¡ˆï¼šç”ŸæˆåŸºç¡€æ‘˜è¦ï¼ˆåŸºäºè§„åˆ™ï¼‰...")
                return self._fallback_analysis(conversation_text, title)
            else:
                logger.warning("âš ï¸  é™çº§æ–¹æ¡ˆå·²ç¦ç”¨ï¼Œè¿”å›None")
                return None
        
        except Exception as e:
            logger.error(f"âŒ åˆ†æå¤±è´¥: {e}")
            
            # é™çº§æ–¹æ¡ˆï¼šç”ŸæˆåŸºç¡€æ‘˜è¦
            if self.config.enable_fallback:
                logger.info("ğŸ”„ å¯åŠ¨é™çº§æ–¹æ¡ˆï¼šç”ŸæˆåŸºç¡€æ‘˜è¦ï¼ˆåŸºäºè§„åˆ™ï¼‰...")
                return self._fallback_analysis(conversation_text, title)
            else:
                logger.warning("âš ï¸  é™çº§æ–¹æ¡ˆå·²ç¦ç”¨ï¼Œè¿”å›None")
                return None
    
    def generate_summary(self, 
                        conversation_text: str,
                        max_words: int = 150) -> Optional[str]:
        """
        å¿«é€Ÿç”Ÿæˆæ‘˜è¦ï¼ˆä¸åŒ…å«åˆ†ç±»å’Œæ ‡ç­¾ï¼‰
        
        Args:
            conversation_text: å¯¹è¯æ–‡æœ¬
            max_words: æœ€å¤§å­—æ•°
        
        Returns:
            æ‘˜è¦æ–‡æœ¬ï¼Œå¤±è´¥è¿”å›None
        """
        if not self.is_available():
            return None
        
        try:
            if isinstance(self.client, OllamaClient):
                return self.client.generate_summary_only(conversation_text, max_words)
            else:
                # å…¶ä»–å®¢æˆ·ç«¯ä½¿ç”¨å®Œæ•´åˆ†æ
                result = self.analyze_conversation(conversation_text)
                return result.summary if result else None
        
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆæ‘˜è¦å¤±è´¥: {e}")
            return None
    
    def generate_tags(self,
                     conversation_text: str,
                     num_tags: int = 5) -> Optional[List[str]]:
        """
        å¿«é€Ÿç”Ÿæˆæ ‡ç­¾
        
        Args:
            conversation_text: å¯¹è¯æ–‡æœ¬
            num_tags: æ ‡ç­¾æ•°é‡
        
        Returns:
            æ ‡ç­¾åˆ—è¡¨ï¼Œå¤±è´¥è¿”å›None
        """
        if not self.is_available():
            return None
        
        try:
            if isinstance(self.client, OllamaClient):
                return self.client.generate_tags_only(conversation_text, num_tags)
            else:
                # å…¶ä»–å®¢æˆ·ç«¯ä½¿ç”¨å®Œæ•´åˆ†æ
                result = self.analyze_conversation(conversation_text)
                return result.tags if result else None
        
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆæ ‡ç­¾å¤±è´¥: {e}")
            return None
    
    def batch_analyze(self,
                     conversations: List[Dict[str, str]],
                     callback=None) -> List[Optional[AIAnalysisResult]]:
        """
        æ‰¹é‡åˆ†æå¯¹è¯
        
        Args:
            conversations: å¯¹è¯åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« 'text' å’Œå¯é€‰çš„ 'title'
            callback: è¿›åº¦å›è°ƒå‡½æ•° callback(current, total)
        
        Returns:
            åˆ†æç»“æœåˆ—è¡¨
        """
        results = []
        total = len(conversations)
        
        for i, conv in enumerate(conversations, 1):
            text = conv.get('text', '')
            title = conv.get('title', '')
            
            result = self.analyze_conversation(text, title)
            results.append(result)
            
            if callback:
                callback(i, total)
        
        return results
    
    def pull_model(self, model_name: str = None) -> bool:
        """
        ä¸‹è½½Ollamaæ¨¡å‹
        
        Args:
            model_name: æ¨¡å‹åç§°ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®çš„æ¨¡å‹
        
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        if not isinstance(self.client, OllamaClient):
            logger.error("åªæœ‰Ollamaåç«¯æ”¯æŒä¸‹è½½æ¨¡å‹")
            return False
        
        import requests
        
        model = model_name or self.config.ollama_model
        
        try:
            logger.info(f"å¼€å§‹ä¸‹è½½æ¨¡å‹: {model}...")
            
            url = f"{self.config.ollama_host}/api/pull"
            response = requests.post(
                url,
                json={"name": model},
                stream=True,
                timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
            )
            
            for line in response.iter_lines():
                if line:
                    import json
                    data = json.loads(line)
                    status = data.get('status', '')
                    
                    if 'total' in data and 'completed' in data:
                        percent = (data['completed'] / data['total']) * 100
                        logger.info(f"ä¸‹è½½è¿›åº¦: {percent:.1f}%")
                    else:
                        logger.info(status)
            
            logger.info(f"âœ… æ¨¡å‹ä¸‹è½½å®Œæˆ: {model}")
            return True
        
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥: {e}")
            return False
    
    def _fallback_analysis(self, 
                           conversation_text: str,
                           title: str = "") -> Optional[AIAnalysisResult]:
        """
        é™çº§åˆ†ææ–¹æ¡ˆï¼ˆå½“AIåˆ†æå¤±è´¥æˆ–è¶…æ—¶æ—¶ï¼‰
        
        ä½¿ç”¨è§„åˆ™æå–è€ŒéAIæ¨¡å‹ï¼š
        1. æå–å‰150å­—ä½œä¸ºæ‘˜è¦
        2. åŸºäºå…³é”®è¯è¿›è¡Œç®€å•åˆ†ç±»
        3. æå–é«˜é¢‘è¯ä½œä¸ºæ ‡ç­¾
        
        Args:
            conversation_text: å¯¹è¯æ–‡æœ¬
            title: å¯¹è¯æ ‡é¢˜
        
        Returns:
            AIAnalysisResultå¯¹è±¡
        """
        try:
            from collections import Counter
            import re
            
            # 1. ç”Ÿæˆç®€å•æ‘˜è¦ï¼ˆå–å‰150å­— + æ ‡é¢˜ï¼‰
            summary = title if title else ""
            if not summary or len(summary) < 20:
                # æå–ç¬¬ä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
                first_msg = conversation_text.split('\n\n')[0] if '\n\n' in conversation_text else conversation_text
                summary = first_msg[:150]
            
            # æ¸…ç†æ‘˜è¦
            summary = summary.strip()
            if len(summary) > 150:
                summary = summary[:147] + "..."
            
            # 2. åŸºäºå…³é”®è¯çš„ç®€å•åˆ†ç±»
            category = self._simple_categorize(conversation_text)
            
            # 3. æå–é«˜é¢‘è¯ä½œä¸ºæ ‡ç­¾
            tags = self._extract_simple_tags(conversation_text)
            
            logger.info(f"âœ… é™çº§åˆ†æå®Œæˆ: {category} | æ ‡ç­¾: {', '.join(tags)}")
            
            return AIAnalysisResult(
                summary=summary or "æ— æ³•ç”Ÿæˆæ‘˜è¦",
                category=category,
                tags=tags,
                confidence=0.3  # é™ä½ç½®ä¿¡åº¦ï¼Œè¡¨æ˜æ˜¯é™çº§æ–¹æ¡ˆ
            )
        
        except Exception as e:
            logger.error(f"âŒ é™çº§åˆ†æä¹Ÿå¤±è´¥: {e}")
            # è¿”å›æœ€åŸºç¡€çš„ç»“æœ
            return AIAnalysisResult(
                summary=title[:100] if title else "å¯¹è¯å†…å®¹",
                category="å…¶ä»–",
                tags=["æœªåˆ†ç±»"],
                confidence=0.1
            )
    
    def _simple_categorize(self, text: str) -> str:
        """åŸºäºå…³é”®è¯çš„ç®€å•åˆ†ç±»"""
        text_lower = text.lower()
        
        # ç¼–ç¨‹ç›¸å…³å…³é”®è¯
        if any(kw in text_lower for kw in [
            'python', 'java', 'javascript', 'code', 'function', 'class',
            'api', 'bug', 'debug', 'git', 'docker', 'database', 'ä»£ç ',
            'ç¼–ç¨‹', 'å‡½æ•°', 'ç®—æ³•', 'sql', 'react', 'vue', 'node'
        ]):
            return "ç¼–ç¨‹"
        
        # å†™ä½œç›¸å…³
        if any(kw in text_lower for kw in [
            'å†™ä½œ', 'æ–‡æ¡ˆ', 'æ–‡ç« ', 'æ¶¦è‰²', 'ä¿®æ”¹', 'ä¼˜åŒ–',
            'write', 'article', 'essay', 'blog', 'åšå®¢'
        ]):
            return "å†™ä½œ"
        
        # å­¦ä¹ ç›¸å…³
        if any(kw in text_lower for kw in [
            'å­¦ä¹ ', 'æ•™ç¨‹', 'å¦‚ä½•', 'æ€ä¹ˆ', 'ä»€ä¹ˆæ˜¯', 'è§£é‡Š',
            'learn', 'tutorial', 'how to', 'what is', 'explain'
        ]):
            return "å­¦ä¹ "
        
        # ç­–åˆ’ç›¸å…³
        if any(kw in text_lower for kw in [
            'æ–¹æ¡ˆ', 'è®¡åˆ’', 'ç­–åˆ’', 'æ´»åŠ¨', 'è¥é”€', 'æ¨å¹¿',
            'plan', 'strategy', 'marketing', 'campaign'
        ]):
            return "ç­–åˆ’"
        
        # ä¼‘é—²å¨±ä¹
        if any(kw in text_lower for kw in [
            'æ¸¸æˆ', 'ç”µå½±', 'éŸ³ä¹', 'å°è¯´', 'æ•…äº‹', 'èŠå¤©',
            'game', 'movie', 'music', 'story', 'chat'
        ]):
            return "ä¼‘é—²å¨±ä¹"
        
        return "å…¶ä»–"
    
    def _extract_simple_tags(self, text: str, max_tags: int = 5) -> List[str]:
        """æå–ç®€å•æ ‡ç­¾ï¼ˆåŸºäºé«˜é¢‘è¯ï¼‰"""
        import re
        from collections import Counter
        
        # åˆ†è¯ï¼ˆç®€å•çš„ç©ºæ ¼å’Œæ ‡ç‚¹åˆ†éš”ï¼‰
        words = re.findall(r'[\w]+', text.lower())
        
        # è¿‡æ»¤åœç”¨è¯å’ŒçŸ­è¯
        stop_words = {
            'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for',
            'of', 'with', 'by', 'from', 'as', 'is', 'was', 'are', 'were', 'be',
            'been', 'being', 'have', 'has', 'had', 'do', 'does', 'did', 'will',
            'would', 'should', 'could', 'may', 'might', 'must', 'can',
            'çš„', 'äº†', 'æ˜¯', 'åœ¨', 'å’Œ', 'æœ‰', 'æˆ‘', 'ä½ ', 'ä»–', 'å¥¹', 'å®ƒ',
            'è¿™', 'é‚£', 'ä¸ª', 'ä»¬', 'å—', 'å‘¢', 'å•Š', 'å“¦', 'å—¯'
        }
        
        # è¿‡æ»¤å’Œç»Ÿè®¡
        words = [w for w in words if len(w) > 2 and w not in stop_words]
        word_freq = Counter(words)
        
        # è·å–é«˜é¢‘è¯
        common_words = word_freq.most_common(max_tags * 2)
        
        # æå–å‰Nä¸ªä½œä¸ºæ ‡ç­¾ï¼ˆé¿å…è¿‡äºé€šç”¨çš„è¯ï¼‰
        tags = []
        for word, freq in common_words:
            if freq > 1 and word not in {'user', 'assistant', 'message', 'conversation'}:
                tags.append(word)
            if len(tags) >= max_tags:
                break
        
        # å¦‚æœæ ‡ç­¾å¤ªå°‘ï¼Œè¡¥å……ä¸€äº›é»˜è®¤æ ‡ç­¾
        if len(tags) < 2:
            tags.append("å¯¹è¯")
        
        return tags[:max_tags]
    
    def test_connection(self) -> Dict[str, Any]:
        """
        æµ‹è¯•AIè¿æ¥
        
        Returns:
            æµ‹è¯•ç»“æœå­—å…¸
        """
        result = {
            'success': False,
            'backend': self.config.backend,
            'message': '',
            'test_response': None
        }
        
        if not self.is_available():
            result['message'] = 'AIæœåŠ¡ä¸å¯ç”¨'
            return result
        
        try:
            # ç®€å•æµ‹è¯•
            test_text = "ç”¨æˆ·: ä½ å¥½\nåŠ©æ‰‹: ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ çš„å—ï¼Ÿ"
            
            logger.info("æ‰§è¡Œè¿æ¥æµ‹è¯•...")
            response = self.client.generate_summary_only(test_text, max_words=20)
            
            if response:
                result['success'] = True
                result['message'] = 'AIæœåŠ¡è¿æ¥æ­£å¸¸'
                result['test_response'] = response
                logger.info("âœ… è¿æ¥æµ‹è¯•æˆåŠŸ")
            else:
                result['message'] = 'AIæœåŠ¡æ— å“åº”'
                logger.warning("âš ï¸ è¿æ¥æµ‹è¯•å¤±è´¥ï¼šæ— å“åº”")
        
        except Exception as e:
            result['message'] = f'è¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}'
            logger.error(f"âŒ è¿æ¥æµ‹è¯•å¼‚å¸¸: {e}")
        
        return result


# å…¨å±€AIæœåŠ¡å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
_ai_service_instance = None


def get_ai_service() -> AIService:
    """è·å–å…¨å±€AIæœåŠ¡å®ä¾‹ï¼ˆå•ä¾‹ï¼‰"""
    global _ai_service_instance
    
    if _ai_service_instance is None:
        _ai_service_instance = AIService()
    
    return _ai_service_instance


def reset_ai_service():
    """é‡ç½®å…¨å±€AIæœåŠ¡å®ä¾‹ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
    global _ai_service_instance
    _ai_service_instance = None


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == '__main__':
    import sys
    
    # åˆ›å»ºAIæœåŠ¡
    ai_service = AIService()
    
    # æ£€æŸ¥çŠ¶æ€
    status = ai_service.get_status()
    print(f"\n{'='*60}")
    print("AIæœåŠ¡çŠ¶æ€")
    print(f"{'='*60}")
    for key, value in status.items():
        print(f"{key}: {value}")
    print(f"{'='*60}\n")
    
    if not status['available']:
        print("âŒ AIæœåŠ¡ä¸å¯ç”¨ï¼Œé€€å‡ºæµ‹è¯•")
        sys.exit(1)
    
    # æµ‹è¯•è¿æ¥
    test_result = ai_service.test_connection()
    print(f"\nè¿æ¥æµ‹è¯•: {'âœ… æˆåŠŸ' if test_result['success'] else 'âŒ å¤±è´¥'}")
    print(f"æ¶ˆæ¯: {test_result['message']}")
    if test_result['test_response']:
        print(f"æµ‹è¯•å“åº”: {test_result['test_response']}")
    
    # æµ‹è¯•åˆ†æ
    test_conversation = """
ç”¨æˆ·: æˆ‘æƒ³å­¦ä¹ Pythonæ•°æ®åˆ†æï¼Œåº”è¯¥ä»å“ªé‡Œå¼€å§‹ï¼Ÿ

åŠ©æ‰‹: å­¦ä¹ Pythonæ•°æ®åˆ†æï¼Œæˆ‘å»ºè®®ï¼š
1. æŒæ¡PythonåŸºç¡€è¯­æ³•
2. å­¦ä¹ NumPyå’ŒPandas
3. äº†è§£æ•°æ®å¯è§†åŒ–
4. å®è·µçœŸå®é¡¹ç›®

ç”¨æˆ·: Pandasæœ‰å“ªäº›å¸¸ç”¨æ“ä½œï¼Ÿ

åŠ©æ‰‹: Pandaså¸¸ç”¨æ“ä½œåŒ…æ‹¬ï¼š
- æ•°æ®è¯»å–: read_csv(), read_excel()
- æ•°æ®ç­›é€‰: loc[], iloc[]
- æ•°æ®æ¸…æ´—: dropna(), fillna()
- æ•°æ®èšåˆ: groupby(), agg()
"""
    
    print(f"\n{'='*60}")
    print("å¯¹è¯åˆ†ææµ‹è¯•")
    print(f"{'='*60}")
    
    result = ai_service.analyze_conversation(test_conversation, "Pythonæ•°æ®åˆ†æå­¦ä¹ ")
    
    if result:
        print(f"\nğŸ“ æ‘˜è¦:\n{result.summary}")
        print(f"\nğŸ“ åˆ†ç±»: {result.category}")
        print(f"\nğŸ·ï¸  æ ‡ç­¾: {', '.join(result.tags)}")
        print(f"\nğŸ“Š ç½®ä¿¡åº¦: {result.confidence}")
    else:
        print("âŒ åˆ†æå¤±è´¥")
    
    print(f"\n{'='*60}\n")
