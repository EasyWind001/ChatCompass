"""
Ollamaæœ¬åœ°å¤§æ¨¡å‹å®¢æˆ·ç«¯
ç”¨äºç”Ÿæˆæ‘˜è¦ã€åˆ†ç±»å’Œæ ‡ç­¾
"""
import json
import requests
from typing import Dict, List, Optional
from dataclasses import dataclass


@dataclass
class AIAnalysisResult:
    """AIåˆ†æç»“æœ"""
    summary: str
    category: str
    tags: List[str]
    confidence: float = 0.0  # ç½®ä¿¡åº¦


class OllamaClient:
    """Ollama APIå®¢æˆ·ç«¯"""
    
    def __init__(self, 
                 base_url: str = None,
                 model: str = None,
                 timeout: int = 180):  # å¢åŠ åˆ°180ç§’
        """
        åˆå§‹åŒ–Ollamaå®¢æˆ·ç«¯
        
        Args:
            base_url: OllamaæœåŠ¡åœ°å€ï¼ˆé»˜è®¤ä»ç¯å¢ƒå˜é‡OLLAMA_HOSTè¯»å–ï¼‰
            model: ä½¿ç”¨çš„æ¨¡å‹åç§°ï¼ˆé»˜è®¤ä»ç¯å¢ƒå˜é‡OLLAMA_MODELè¯»å–ï¼Œæ¨èqwen2.5:3bï¼‰
            timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤180ç§’ç”¨äºå¤„ç†å¤§æ–‡æœ¬
        """
        import os
        
        self.base_url = (base_url or os.getenv('OLLAMA_HOST', 'http://localhost:11434')).rstrip('/')
        self.model = model or os.getenv('OLLAMA_MODEL', 'qwen2.5:3b')
        self.timeout = timeout
        self.api_url = f"{self.base_url}/api/generate"
    
    def is_available(self) -> bool:
        """æ£€æŸ¥OllamaæœåŠ¡æ˜¯å¦å¯ç”¨"""
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=5)
            return response.status_code == 200
        except:
            return False
    
    def list_models(self) -> List[str]:
        """åˆ—å‡ºå¯ç”¨çš„æ¨¡å‹"""
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=5)
            if response.status_code == 200:
                data = response.json()
                return [model['name'] for model in data.get('models', [])]
        except:
            pass
        return []
    
    def generate(self, prompt: str, system_prompt: str = None, show_progress: bool = False) -> str:
        """
        è°ƒç”¨Ollamaç”Ÿæˆæ–‡æœ¬
        
        Args:
            prompt: ç”¨æˆ·æç¤ºè¯
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            show_progress: æ˜¯å¦æ˜¾ç¤ºæµå¼è¿›åº¦ï¼ˆç”¨äºå¤§æ–‡æœ¬ï¼‰
        
        Returns:
            ç”Ÿæˆçš„æ–‡æœ¬
        """
        import logging
        logger = logging.getLogger(__name__)
        
        payload = {
            "model": self.model,
            "prompt": prompt,
            "stream": show_progress,  # å¤§æ–‡æœ¬æ—¶ä½¿ç”¨æµå¼è¾“å‡º
            "options": {
                "temperature": 0.3,  # é™ä½éšæœºæ€§ï¼Œæé«˜ç¨³å®šæ€§
                "top_p": 0.9,
            }
        }
        
        if system_prompt:
            payload["system"] = system_prompt
        
        try:
            if show_progress:
                # æµå¼å“åº”ï¼ˆæ˜¾ç¤ºè¿›åº¦ï¼‰
                import sys
                response = requests.post(
                    self.api_url,
                    json=payload,
                    timeout=self.timeout,
                    stream=True
                )
                response.raise_for_status()
                
                full_response = ""
                logger.info("â³ æ­£åœ¨ç”Ÿæˆå›å¤...")
                
                for line in response.iter_lines():
                    if line:
                        data = json.loads(line)
                        chunk = data.get('response', '')
                        full_response += chunk
                        
                        # æ˜¾ç¤ºè¿›åº¦ç‚¹
                        if data.get('done'):
                            logger.info("âœ… ç”Ÿæˆå®Œæˆ")
                        else:
                            # æ¯10ä¸ªå­—ç¬¦æ˜¾ç¤ºä¸€ä¸ªè¿›åº¦ç‚¹
                            if len(full_response) % 10 == 0:
                                sys.stderr.write('.')
                                sys.stderr.flush()
                
                sys.stderr.write('\n')
                return full_response.strip()
            else:
                # éæµå¼å“åº”
                response = requests.post(
                    self.api_url,
                    json=payload,
                    timeout=self.timeout
                )
                response.raise_for_status()
                
                result = response.json()
                return result.get('response', '').strip()
            
        except requests.Timeout:
            raise TimeoutError(f"Ollamaè¯·æ±‚è¶…æ—¶ï¼ˆ{self.timeout}ç§’ï¼‰ï¼Œå»ºè®®åˆ†æ‰¹å¤„ç†æˆ–å¢åŠ è¶…æ—¶æ—¶é—´")
        except requests.RequestException as e:
            raise RuntimeError(f"Ollamaè¯·æ±‚å¤±è´¥: {str(e)}")
    
    def analyze_conversation(self, conversation_text: str) -> AIAnalysisResult:
        """
        åˆ†æå¯¹è¯å†…å®¹ï¼Œç”Ÿæˆæ‘˜è¦ã€åˆ†ç±»å’Œæ ‡ç­¾
        
        ä½¿ç”¨åˆ†æ®µæ‘˜è¦åˆå¹¶ç­–ç•¥å¤„ç†é•¿æ–‡æœ¬ï¼š
        1. æ£€æµ‹åˆ°è¶…é•¿æ–‡æœ¬æ—¶ï¼ŒæŒ‰å¯¹è¯è½®æ¬¡åˆ†æ®µ
        2. å¯¹æ¯æ®µç”Ÿæˆæ‘˜è¦ï¼ˆå¹¶è¡Œå¤„ç†ï¼‰
        3. åˆå¹¶æ‰€æœ‰æ‘˜è¦å†ç”Ÿæˆæœ€ç»ˆç»“æœ
        
        Args:
            conversation_text: å®Œæ•´å¯¹è¯æ–‡æœ¬
        
        Returns:
            AIAnalysisResultå¯¹è±¡
        """
        import logging
        logger = logging.getLogger(__name__)
        
        # æ˜¾ç¤ºå¤„ç†æç¤º
        text_length = len(conversation_text)
        logger.info(f"ğŸ“Š å¼€å§‹åˆ†æå¯¹è¯ï¼ˆ{text_length:,} å­—ç¬¦ï¼‰...")
        
        # åˆ†æ®µæ‘˜è¦ç­–ç•¥ï¼šè¶…è¿‡é˜ˆå€¼æ—¶ä½¿ç”¨
        segment_threshold = 12000  # 12000å­—ç¬¦å¼€å§‹åˆ†æ®µ
        max_segment_length = 6000  # æ¯æ®µæœ€å¤š6000å­—ç¬¦
        
        if text_length >= segment_threshold:
            logger.info(f"ğŸ’¡ æ£€æµ‹åˆ°è¶…é•¿æ–‡æœ¬ï¼Œå¯ç”¨åˆ†æ®µæ‘˜è¦ç­–ç•¥...")
            return self._analyze_with_segments(conversation_text)
        else:
            # çŸ­æ–‡æœ¬ç›´æ¥åˆ†æ
            return self._analyze_direct(conversation_text)
    
    def _analyze_direct(self, conversation_text: str) -> AIAnalysisResult:
        """ç›´æ¥åˆ†æï¼ˆçŸ­æ–‡æœ¬ï¼‰"""
        import logging
        logger = logging.getLogger(__name__)
        
        # å¦‚æœä»ç„¶è¶…è¿‡8000å­—ç¬¦ï¼Œåšç®€å•æˆªæ–­
        max_length = 8000
        if len(conversation_text) > max_length:
            logger.warning(f"âš ï¸  æ–‡æœ¬è¶…è¿‡{max_length}å­—ç¬¦ï¼Œæˆªå–å…³é”®éƒ¨åˆ†ï¼ˆå‰70%+å30%ï¼‰")
            head_length = int(max_length * 0.7)
            tail_length = int(max_length * 0.3)
            conversation_text = (
                conversation_text[:head_length] + 
                "\n\n...[ä¸­é—´å†…å®¹å·²çœç•¥]...\n\n" +
                conversation_text[-tail_length:]
            )
        
        # æ„å»ºæç¤ºè¯
        logger.info("ğŸ”„ æ­£åœ¨è°ƒç”¨AIæ¨¡å‹...")
        prompt = self._build_analysis_prompt(conversation_text)
        system_prompt = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIå¯¹è¯åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿æå–å…³é”®ä¿¡æ¯ã€ç”Ÿæˆæ‘˜è¦å’Œåˆ†ç±»ã€‚"
        
        # è°ƒç”¨æ¨¡å‹
        response = self.generate(prompt, system_prompt)
        
        logger.info("âœ… AIåˆ†æå®Œæˆï¼Œæ­£åœ¨è§£æç»“æœ...")
        
        # è§£æç»“æœ
        return self._parse_analysis_result(response)
    
    def _analyze_with_segments(self, conversation_text: str) -> AIAnalysisResult:
        """åˆ†æ®µåˆ†æï¼ˆè¶…é•¿æ–‡æœ¬ï¼‰"""
        import logging
        logger = logging.getLogger(__name__)
        
        # æ­¥éª¤1ï¼šæ™ºèƒ½åˆ†æ®µï¼ˆæŒ‰å¯¹è¯è½®æ¬¡ï¼‰
        segments = self._split_into_segments(conversation_text)
        logger.info(f"ğŸ“¦ å·²åˆ†ä¸º {len(segments)} æ®µï¼ˆæ¯æ®µçº¦ {len(conversation_text)//len(segments):,} å­—ç¬¦ï¼‰")
        
        # æ­¥éª¤2ï¼šå¯¹æ¯æ®µç”Ÿæˆæ‘˜è¦
        segment_summaries = []
        for i, segment in enumerate(segments, 1):
            logger.info(f"ğŸ” æ­£åœ¨åˆ†æç¬¬ {i}/{len(segments)} æ®µ...")
            summary = self._summarize_segment(segment, i)
            segment_summaries.append(summary)
            logger.info(f"  âœ… ç¬¬ {i} æ®µæ‘˜è¦: {summary[:60]}...")
        
        # æ­¥éª¤3ï¼šåˆå¹¶æ‘˜è¦
        logger.info(f"ğŸ”— åˆå¹¶ {len(segment_summaries)} ä¸ªåˆ†æ®µæ‘˜è¦...")
        combined_summary = "\n\n".join([
            f"[ç¬¬{i+1}æ®µ] {summary}" 
            for i, summary in enumerate(segment_summaries)
        ])
        
        # æ­¥éª¤4ï¼šåŸºäºåˆå¹¶æ‘˜è¦ç”Ÿæˆæœ€ç»ˆç»“æœ
        logger.info("ğŸ¯ ç”Ÿæˆæœ€ç»ˆåˆ†æç»“æœ...")
        final_prompt = f"""åŸºäºä»¥ä¸‹åˆ†æ®µæ‘˜è¦ï¼Œç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„å¯¹è¯åˆ†æï¼š

{combined_summary}

è¯·æä¾›ï¼š
1. æ•´ä½“æ‘˜è¦ï¼ˆ100-150å­—ï¼Œæ¦‚æ‹¬æ‰€æœ‰æ®µè½çš„æ ¸å¿ƒå†…å®¹ï¼‰
2. ä¸»è¦åˆ†ç±»ï¼ˆä»ï¼šç¼–ç¨‹ã€å†™ä½œã€å­¦ä¹ ã€ç­–åˆ’ã€ä¼‘é—²å¨±ä¹ã€å…¶ä»– ä¸­é€‰æ‹©æœ€åˆé€‚çš„ï¼‰
3. å…³é”®æ ‡ç­¾ï¼ˆ3-5ä¸ªï¼Œæå–æœ€é‡è¦çš„ä¸»é¢˜è¯ï¼‰
4. ç½®ä¿¡åº¦ï¼ˆ0-1ä¹‹é—´çš„æµ®ç‚¹æ•°ï¼‰

JSONæ ¼å¼è¾“å‡ºï¼š
{{
  "summary": "...",
  "category": "...",
  "tags": ["tag1", "tag2", "tag3"],
  "confidence": 0.85
}}"""
        
        system_prompt = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIå¯¹è¯åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿ä»å¤šä¸ªåˆ†æ®µæ‘˜è¦ä¸­æå–æ•´ä½“ä¿¡æ¯ã€‚"
        response = self.generate(final_prompt, system_prompt)
        
        logger.info("âœ… åˆ†æ®µåˆ†æå®Œæˆ")
        
        return self._parse_analysis_result(response)
    
    def _split_into_segments(self, text: str, max_segment_length: int = 6000) -> list:
        """
        æ™ºèƒ½åˆ†æ®µï¼šæŒ‰å¯¹è¯è½®æ¬¡åˆ†å‰²
        
        ä¼˜å…ˆåœ¨å¯¹è¯è¾¹ç•Œï¼ˆUser/Assistantï¼‰å¤„åˆ†å‰²ï¼Œé¿å…æˆªæ–­å•æ¡æ¶ˆæ¯
        """
        # å¤„ç†ç©ºæ–‡æœ¬æˆ–æçŸ­æ–‡æœ¬
        if not text or len(text) <= max_segment_length:
            return [text] if text else []
        
        # å°è¯•æŒ‰å¯¹è¯è½®æ¬¡åˆ†å‰²ï¼ˆå¸¸è§çš„åˆ†éš”ç¬¦ï¼‰
        separators = [
            '\n\nUser:',
            '\n\nAssistant:',
            '\n\nç”¨æˆ·:',
            '\n\nåŠ©æ‰‹:',
            '\n\n## ',
            '\n\n### ',
            '\n\n---',
            '\n\n'
        ]
        
        segments = []
        remaining_text = text
        
        while len(remaining_text) > max_segment_length:
            # åœ¨max_segment_lengthé™„è¿‘æ‰¾æœ€ä½³åˆ†å‰²ç‚¹
            search_start = max(0, max_segment_length - 500)
            search_end = min(len(remaining_text), max_segment_length + 500)
            search_range = remaining_text[search_start:search_end]
            
            # å¯»æ‰¾æœ€è¿‘çš„åˆ†éš”ç¬¦
            best_split = -1
            for separator in separators:
                pos = search_range.rfind(separator)
                if pos != -1:
                    best_split = search_start + pos
                    break
            
            # å¦‚æœæ‰¾ä¸åˆ°åˆ†éš”ç¬¦ï¼Œå¼ºåˆ¶åœ¨max_segment_lengthå¤„åˆ†å‰²
            if best_split == -1:
                best_split = max_segment_length
            
            # åˆ†å‰²
            segments.append(remaining_text[:best_split].strip())
            remaining_text = remaining_text[best_split:].strip()
        
        # æ·»åŠ æœ€åä¸€æ®µ
        if remaining_text:
            segments.append(remaining_text)
        
        return segments
    
    def _summarize_segment(self, segment: str, segment_num: int) -> str:
        """
        å¯¹å•ä¸ªåˆ†æ®µç”Ÿæˆæ‘˜è¦
        
        Args:
            segment: åˆ†æ®µæ–‡æœ¬
            segment_num: åˆ†æ®µåºå·
        
        Returns:
            è¯¥æ®µçš„æ‘˜è¦ï¼ˆ100-150å­—ï¼‰
        """
        prompt = f"""è¯·ä¸ºä»¥ä¸‹å¯¹è¯ç‰‡æ®µç”Ÿæˆç®€æ´æ‘˜è¦ï¼ˆ100-150å­—ï¼‰ï¼š

{segment[:3000]}  {'...(åç»­å†…å®¹çœç•¥)' if len(segment) > 3000 else ''}

æ‘˜è¦è¦æ±‚ï¼š
1. æ¦‚æ‹¬è¿™æ®µå¯¹è¯çš„ä¸»è¦å†…å®¹å’Œç»“è®º
2. ä¿ç•™å…³é”®ä¿¡æ¯ï¼ˆé—®é¢˜ã€è§£å†³æ–¹æ¡ˆã€é‡è¦è§‚ç‚¹ï¼‰
3. 100-150å­—ä»¥å†…
4. ç›´æ¥è¾“å‡ºæ‘˜è¦æ–‡æœ¬ï¼Œä¸è¦é¢å¤–è§£é‡Š

æ‘˜è¦ï¼š"""
        
        system_prompt = f"ä½ æ˜¯ä¸€ä¸ªæ‘˜è¦ç”ŸæˆåŠ©æ‰‹ï¼Œæ­£åœ¨å¤„ç†é•¿å¯¹è¯çš„ç¬¬{segment_num}æ®µã€‚"
        
        try:
            summary = self.generate(prompt, system_prompt)
            return summary.strip()
        except Exception as e:
            # é™çº§ï¼šè¿”å›å‰150å­—
            return segment[:150] + "..."
    
    def _build_analysis_prompt(self, conversation_text: str) -> str:
        """æ„å»ºåˆ†ææç¤ºè¯"""
        prompt = f"""è¯·åˆ†æä»¥ä¸‹AIå¯¹è¯å†…å®¹ï¼Œå¹¶æŒ‰ç…§JSONæ ¼å¼è¿”å›ç»“æœï¼š

å¯¹è¯å†…å®¹ï¼š
{conversation_text}

è¯·æä¾›ï¼š
1. summary: ä¸€ä¸ªç®€æ´çš„æ‘˜è¦ï¼ˆ100-150å­—ï¼‰ï¼Œæ¦‚æ‹¬å¯¹è¯çš„æ ¸å¿ƒä¸»é¢˜å’Œå…³é”®ç»“è®º
2. category: ä¸»è¦åˆ†ç±»ï¼Œä»ä»¥ä¸‹é€‰é¡¹ä¸­é€‰æ‹©ä¸€ä¸ªï¼šç¼–ç¨‹ã€å†™ä½œã€å­¦ä¹ ã€ç­–åˆ’ã€ä¼‘é—²å¨±ä¹ã€å…¶ä»–
3. tags: 3-5ä¸ªå…³é”®è¯æ ‡ç­¾ï¼ˆä¾‹å¦‚ï¼šPythonã€æœºå™¨å­¦ä¹ ã€æ•°æ®åˆ†æç­‰ï¼‰

è¿”å›æ ¼å¼ï¼ˆå¿…é¡»æ˜¯æœ‰æ•ˆçš„JSONï¼‰ï¼š
{{
    "summary": "å¯¹è¯æ‘˜è¦å†…å®¹...",
    "category": "ç¼–ç¨‹",
    "tags": ["Python", "æ•°æ®åˆ†æ", "pandas"]
}}

è¯·ç›´æ¥è¿”å›JSONï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–æ–‡å­—è¯´æ˜ã€‚"""
        
        return prompt
    
    def _parse_analysis_result(self, response: str) -> AIAnalysisResult:
        """è§£æAIè¿”å›çš„åˆ†æç»“æœ"""
        try:
            # å°è¯•æå–JSONï¼ˆå¤„ç†å¯èƒ½çš„markdownä»£ç å—ï¼‰
            json_text = response
            
            # ç§»é™¤å¯èƒ½çš„markdownä»£ç å—æ ‡è®°
            if '```json' in json_text:
                json_text = json_text.split('```json')[1].split('```')[0]
            elif '```' in json_text:
                json_text = json_text.split('```')[1].split('```')[0]
            
            # è§£æJSON
            data = json.loads(json_text.strip())
            
            return AIAnalysisResult(
                summary=data.get('summary', '').strip(),
                category=data.get('category', 'å…¶ä»–').strip(),
                tags=data.get('tags', []),
                confidence=0.8
            )
            
        except json.JSONDecodeError:
            # JSONè§£æå¤±è´¥ï¼Œå°è¯•æ‰‹åŠ¨æå–
            print(f"[è­¦å‘Š] JSONè§£æå¤±è´¥ï¼Œå°è¯•æ‰‹åŠ¨æå–ã€‚åŸå§‹å“åº”:\n{response}")
            return self._fallback_parse(response)
    
    def _fallback_parse(self, response: str) -> AIAnalysisResult:
        """å¤‡ç”¨è§£ææ–¹æ³•ï¼ˆå½“JSONè§£æå¤±è´¥æ—¶ï¼‰"""
        import re
        
        # å°è¯•æå–æ‘˜è¦
        summary_match = re.search(r'"summary"\s*:\s*"([^"]+)"', response)
        summary = summary_match.group(1) if summary_match else response[:150]
        
        # å°è¯•æå–åˆ†ç±»
        category_match = re.search(r'"category"\s*:\s*"([^"]+)"', response)
        category = category_match.group(1) if category_match else "å…¶ä»–"
        
        # å°è¯•æå–æ ‡ç­¾
        tags_match = re.search(r'"tags"\s*:\s*\[(.*?)\]', response)
        tags = []
        if tags_match:
            tags_str = tags_match.group(1)
            tags = [t.strip(' "\'') for t in tags_str.split(',')]
        
        return AIAnalysisResult(
            summary=summary,
            category=category,
            tags=tags,
            confidence=0.5  # é™ä½ç½®ä¿¡åº¦
        )
    
    def generate_summary_only(self, conversation_text: str, max_words: int = 150) -> str:
        """ä»…ç”Ÿæˆæ‘˜è¦ï¼ˆå¿«é€Ÿæ¨¡å¼ï¼‰"""
        prompt = f"""è¯·ä¸ºä»¥ä¸‹å¯¹è¯ç”Ÿæˆä¸€ä¸ªç®€æ´çš„æ‘˜è¦ï¼ˆä¸è¶…è¿‡{max_words}å­—ï¼‰ï¼š

{conversation_text[:5000]}

æ‘˜è¦ï¼š"""
        
        return self.generate(prompt)
    
    def generate_tags_only(self, conversation_text: str, num_tags: int = 5) -> List[str]:
        """ä»…ç”Ÿæˆæ ‡ç­¾ï¼ˆå¿«é€Ÿæ¨¡å¼ï¼‰"""
        prompt = f"""è¯·ä¸ºä»¥ä¸‹å¯¹è¯æå–{num_tags}ä¸ªå…³é”®è¯æ ‡ç­¾ï¼Œç”¨é€—å·åˆ†éš”ï¼š

{conversation_text[:3000]}

æ ‡ç­¾ï¼š"""
        
        response = self.generate(prompt)
        
        # è§£ææ ‡ç­¾
        tags = [tag.strip() for tag in response.split(',')]
        return tags[:num_tags]


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == '__main__':
    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    client = OllamaClient(model="qwen2.5:7b")
    
    # æ£€æŸ¥æœåŠ¡æ˜¯å¦å¯ç”¨
    if not client.is_available():
        print("é”™è¯¯: OllamaæœåŠ¡ä¸å¯ç”¨ï¼Œè¯·ç¡®ä¿å·²å¯åŠ¨Ollama")
        print("å¯åŠ¨å‘½ä»¤: ollama serve")
        exit(1)
    
    print(f"å¯ç”¨æ¨¡å‹: {client.list_models()}")
    
    # æµ‹è¯•å¯¹è¯
    test_conversation = """
ç”¨æˆ·: ä½ å¥½ï¼Œæˆ‘æƒ³å­¦ä¹ Pythonæ•°æ®åˆ†æï¼Œåº”è¯¥ä»å“ªé‡Œå¼€å§‹ï¼Ÿ

åŠ©æ‰‹: å¾ˆé«˜å…´å¸®åŠ©ä½ ï¼å­¦ä¹ Pythonæ•°æ®åˆ†æï¼Œæˆ‘å»ºè®®æŒ‰ä»¥ä¸‹æ­¥éª¤ï¼š

1. æŒæ¡PythonåŸºç¡€è¯­æ³•
2. å­¦ä¹ NumPyå’ŒPandasåº“
3. äº†è§£æ•°æ®å¯è§†åŒ–ï¼ˆMatplotlibã€Seabornï¼‰
4. å®è·µé¡¹ç›®

ç”¨æˆ·: Pandasæœ‰å“ªäº›å¸¸ç”¨çš„æ•°æ®æ“ä½œï¼Ÿ

åŠ©æ‰‹: Pandasçš„å¸¸ç”¨æ“ä½œåŒ…æ‹¬ï¼š
- æ•°æ®è¯»å–ï¼šread_csv(), read_excel()
- æ•°æ®ç­›é€‰ï¼šloc[], iloc[]
- æ•°æ®æ¸…æ´—ï¼šdropna(), fillna()
- æ•°æ®èšåˆï¼šgroupby(), agg()
"""
    
    try:
        print("\nå¼€å§‹åˆ†æå¯¹è¯...")
        result = client.analyze_conversation(test_conversation)
        
        print(f"\næ‘˜è¦: {result.summary}")
        print(f"åˆ†ç±»: {result.category}")
        print(f"æ ‡ç­¾: {', '.join(result.tags)}")
        print(f"ç½®ä¿¡åº¦: {result.confidence}")
        
    except Exception as e:
        print(f"é”™è¯¯: {e}")
