#!/usr/bin/env python3
"""
åˆ†æ®µæ‘˜è¦ç­–ç•¥æµ‹è¯•è„šæœ¬
æ¼”ç¤ºå¦‚ä½•å¤„ç†è¶…é•¿å¯¹è¯
"""
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from ai.ollama_client import OllamaClient
from ai.ai_service import AIConfig


def generate_long_conversation(num_turns: int = 20) -> str:
    """ç”Ÿæˆæ¨¡æ‹Ÿçš„é•¿å¯¹è¯"""
    conversation = []
    
    topics = [
        ("Dockeré•œåƒä¼˜åŒ–", "å¤šé˜¶æ®µæ„å»ºçš„æœ€ä½³å®è·µæ˜¯ä»€ä¹ˆï¼Ÿ", "å¯ä»¥ä½¿ç”¨å¤šé˜¶æ®µæ„å»º..."),
        ("åŸºç¡€é•œåƒé€‰æ‹©", "Alpineå’ŒUbuntuå“ªä¸ªæ›´å¥½ï¼Ÿ", "è¿™å–å†³äºä½ çš„éœ€æ±‚..."),
        ("ä¾èµ–ç®¡ç†", "å¦‚ä½•ä¼˜åŒ–Pythonä¾èµ–å®‰è£…ï¼Ÿ", "å¯ä»¥ä½¿ç”¨requirements.txtåˆ†å±‚..."),
        ("ç¼“å­˜ç­–ç•¥", "å¦‚ä½•åˆ©ç”¨Dockerå±‚ç¼“å­˜ï¼Ÿ", "åˆç†å®‰æ’DockerfileæŒ‡ä»¤é¡ºåº..."),
        ("å®‰å…¨æ‰«æ", "å¦‚ä½•æ‰«æé•œåƒæ¼æ´ï¼Ÿ", "å¯ä»¥ä½¿ç”¨Trivyæˆ–Snyk..."),
    ]
    
    for i in range(num_turns):
        topic, question, answer = topics[i % len(topics)]
        
        # ç”¨æˆ·é—®é¢˜
        conversation.append(f"User: å…³äº{topic}ï¼Œ{question}")
        
        # AIå›ç­”ï¼ˆæ¨¡æ‹Ÿé•¿å›ç­”ï¼‰
        full_answer = f"""Assistant: {answer}

è®©æˆ‘è¯¦ç»†è§£é‡Šä¸€ä¸‹ï¼š

1. é¦–å…ˆï¼Œ{topic}çš„æ ¸å¿ƒåŸç†æ˜¯...
   - è¿™æ ·åšå¯ä»¥...
   - éœ€è¦æ³¨æ„çš„æ˜¯...

2. å…¶æ¬¡ï¼Œåœ¨å®é™…åº”ç”¨ä¸­ï¼š
   ```dockerfile
   # ç¤ºä¾‹ä»£ç 
   FROM python:3.9-slim
   WORKDIR /app
   COPY requirements.txt .
   RUN pip install -r requirements.txt
   ```

3. æœ€åï¼Œä¸€äº›æœ€ä½³å®è·µï¼š
   - ä¼˜åŒ–ç‚¹1ï¼š...
   - ä¼˜åŒ–ç‚¹2ï¼š...
   - ä¼˜åŒ–ç‚¹3ï¼š...

è¿™æ ·å¯ä»¥æ˜¾è‘—æå‡æ€§èƒ½å’Œå®‰å…¨æ€§ã€‚è¿˜æœ‰ä»€ä¹ˆæƒ³äº†è§£çš„å—ï¼Ÿ
"""
        conversation.append(full_answer)
        
        # ç”¨æˆ·è¿½é—®
        if i % 3 == 0:
            conversation.append(f"User: èƒ½å¦ç»™ä¸ªå®Œæ•´çš„ä¾‹å­ï¼Ÿ")
            conversation.append(f"Assistant: å½“ç„¶ï¼è¿™é‡Œæœ‰ä¸ªå®Œæ•´çš„{topic}å®ä¾‹...")
    
    return "\n\n".join(conversation)


def test_short_text():
    """æµ‹è¯•1ï¼šçŸ­æ–‡æœ¬ï¼ˆç›´æ¥åˆ†æï¼‰"""
    print("="*60)
    print("æµ‹è¯•1: çŸ­æ–‡æœ¬ï¼ˆ5000å­—ç¬¦ï¼‰")
    print("="*60)
    
    # ç”ŸæˆçŸ­å¯¹è¯
    conversation = generate_long_conversation(3)  # çº¦5000å­—ç¬¦
    print(f"æ–‡æœ¬é•¿åº¦: {len(conversation):,} å­—ç¬¦")
    
    # åˆ†æ
    config = AIConfig.from_env()
    client = OllamaClient(
        base_url=config.ollama_host,
        model=config.ollama_model,
        timeout=config.timeout
    )
    
    try:
        result = client.analyze_conversation(conversation)
        print(f"\nâœ… åˆ†æç»“æœ:")
        print(f"   æ‘˜è¦: {result.summary}")
        print(f"   åˆ†ç±»: {result.category}")
        print(f"   æ ‡ç­¾: {', '.join(result.tags)}")
        print(f"   ç½®ä¿¡åº¦: {result.confidence}")
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")


def test_medium_text():
    """æµ‹è¯•2ï¼šä¸­é•¿æ–‡æœ¬ï¼ˆåˆ†æ®µåˆ†æ 2-3æ®µï¼‰"""
    print("\n" + "="*60)
    print("æµ‹è¯•2: ä¸­é•¿æ–‡æœ¬ï¼ˆ15000å­—ç¬¦ï¼‰")
    print("="*60)
    
    # ç”Ÿæˆä¸­ç­‰å¯¹è¯
    conversation = generate_long_conversation(10)  # çº¦15000å­—ç¬¦
    print(f"æ–‡æœ¬é•¿åº¦: {len(conversation):,} å­—ç¬¦")
    print(f"é¢„æœŸåˆ†æ®µ: 2-3æ®µ")
    
    # åˆ†æ
    config = AIConfig.from_env()
    client = OllamaClient(
        base_url=config.ollama_host,
        model=config.ollama_model,
        timeout=config.timeout
    )
    
    try:
        result = client.analyze_conversation(conversation)
        print(f"\nâœ… åˆ†æç»“æœ:")
        print(f"   æ‘˜è¦: {result.summary}")
        print(f"   åˆ†ç±»: {result.category}")
        print(f"   æ ‡ç­¾: {', '.join(result.tags)}")
        print(f"   ç½®ä¿¡åº¦: {result.confidence}")
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")


def test_long_text():
    """æµ‹è¯•3ï¼šè¶…é•¿æ–‡æœ¬ï¼ˆåˆ†æ®µåˆ†æ 5-6æ®µï¼‰"""
    print("\n" + "="*60)
    print("æµ‹è¯•3: è¶…é•¿æ–‡æœ¬ï¼ˆ30000å­—ç¬¦ï¼‰")
    print("="*60)
    
    # ç”Ÿæˆè¶…é•¿å¯¹è¯
    conversation = generate_long_conversation(20)  # çº¦30000å­—ç¬¦
    print(f"æ–‡æœ¬é•¿åº¦: {len(conversation):,} å­—ç¬¦")
    print(f"é¢„æœŸåˆ†æ®µ: 5-6æ®µ")
    
    # åˆ†æ
    config = AIConfig.from_env()
    client = OllamaClient(
        base_url=config.ollama_host,
        model=config.ollama_model,
        timeout=config.timeout
    )
    
    try:
        result = client.analyze_conversation(conversation)
        print(f"\nâœ… åˆ†æç»“æœ:")
        print(f"   æ‘˜è¦: {result.summary}")
        print(f"   åˆ†ç±»: {result.category}")
        print(f"   æ ‡ç­¾: {', '.join(result.tags)}")
        print(f"   ç½®ä¿¡åº¦: {result.confidence}")
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")


def test_segment_algorithm():
    """æµ‹è¯•4ï¼šåˆ†æ®µç®—æ³•"""
    print("\n" + "="*60)
    print("æµ‹è¯•4: æ™ºèƒ½åˆ†æ®µç®—æ³•")
    print("="*60)
    
    # ç”Ÿæˆæµ‹è¯•æ–‡æœ¬
    conversation = generate_long_conversation(15)  # çº¦22000å­—ç¬¦
    print(f"åŸå§‹æ–‡æœ¬é•¿åº¦: {len(conversation):,} å­—ç¬¦\n")
    
    # æµ‹è¯•åˆ†æ®µ
    config = AIConfig.from_env()
    client = OllamaClient(
        base_url=config.ollama_host,
        model=config.ollama_model,
        timeout=config.timeout
    )
    
    segments = client._split_into_segments(conversation)
    
    print(f"åˆ†æ®µç»“æœ:")
    print(f"  æ€»æ®µæ•°: {len(segments)}")
    for i, segment in enumerate(segments, 1):
        print(f"  ç¬¬{i}æ®µ: {len(segment):>6,} å­—ç¬¦ | é¢„è§ˆ: {segment[:50]}...")
    
    # éªŒè¯åˆ†æ®µè´¨é‡
    total_length = sum(len(s) for s in segments)
    print(f"\nåˆ†æ®µè´¨é‡æ£€æŸ¥:")
    print(f"  åŸå§‹é•¿åº¦: {len(conversation):,} å­—ç¬¦")
    print(f"  åˆ†æ®µæ€»å’Œ: {total_length:,} å­—ç¬¦")
    print(f"  å·®å¼‚: {abs(len(conversation) - total_length)} å­—ç¬¦")
    
    # æ£€æŸ¥æ˜¯å¦åœ¨å¯¹è¯è¾¹ç•Œåˆ†å‰²
    boundary_splits = 0
    for i, segment in enumerate(segments[:-1]):  # é™¤æœ€åä¸€æ®µ
        if any(segment.strip().endswith(sep.strip()) 
               for sep in ['User:', 'Assistant:', 'ç”¨æˆ·:', 'åŠ©æ‰‹:']):
            boundary_splits += 1
    
    print(f"  è¾¹ç•Œåˆ†å‰²: {boundary_splits}/{len(segments)-1} ({boundary_splits/(len(segments)-1)*100:.0f}%)")


def compare_strategies():
    """æµ‹è¯•5ï¼šç­–ç•¥å¯¹æ¯”"""
    print("\n" + "="*60)
    print("æµ‹è¯•5: ç®€å•æˆªæ–­ vs åˆ†æ®µåˆå¹¶ç­–ç•¥å¯¹æ¯”")
    print("="*60)
    
    # ç”Ÿæˆæµ‹è¯•å¯¹è¯
    conversation = generate_long_conversation(20)  # çº¦30000å­—ç¬¦
    print(f"æµ‹è¯•æ–‡æœ¬: {len(conversation):,} å­—ç¬¦\n")
    
    config = AIConfig.from_env()
    client = OllamaClient(
        base_url=config.ollama_host,
        model=config.ollama_model,
        timeout=config.timeout
    )
    
    # ç­–ç•¥1ï¼šç®€å•æˆªæ–­ï¼ˆæ¨¡æ‹Ÿæ—§æ–¹æ³•ï¼‰
    print("ã€ç­–ç•¥1ï¼šç®€å•æˆªæ–­ã€‘")
    max_length = 8000
    head_length = int(max_length * 0.7)
    tail_length = int(max_length * 0.3)
    truncated = (
        conversation[:head_length] + 
        "\n\n...[ä¸­é—´å†…å®¹å·²çœç•¥]...\n\n" +
        conversation[-tail_length:]
    )
    print(f"  æˆªæ–­åé•¿åº¦: {len(truncated):,} å­—ç¬¦")
    print(f"  ä¿ç•™ç‡: {len(truncated)/len(conversation)*100:.1f}%")
    print(f"  ä¸¢å¤±å†…å®¹: çº¦ {len(conversation) - len(truncated):,} å­—ç¬¦")
    
    # ç­–ç•¥2ï¼šåˆ†æ®µåˆå¹¶ï¼ˆæ–°æ–¹æ³•ï¼‰
    print("\nã€ç­–ç•¥2ï¼šåˆ†æ®µåˆå¹¶ã€‘")
    segments = client._split_into_segments(conversation)
    print(f"  åˆ†æ®µæ•°: {len(segments)}")
    print(f"  æ¯æ®µé•¿åº¦: {[len(s) for s in segments]}")
    print(f"  ä¿ç•™ç‡: 100%ï¼ˆé€šè¿‡æ‘˜è¦ä¿ç•™æ‰€æœ‰æ®µè½çš„å…³é”®ä¿¡æ¯ï¼‰")
    print(f"  ä¼˜åŠ¿: è¦†ç›–å®Œæ•´å¯¹è¯æµç¨‹ï¼Œä¸ä¸¢å¤±ä¸­é—´è®¨è®º")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª åˆ†æ®µæ‘˜è¦ç­–ç•¥æµ‹è¯•")
    print()
    
    # æ£€æŸ¥AIæœåŠ¡
    config = AIConfig.from_env()
    if not config.enabled:
        print("âŒ AIåŠŸèƒ½æœªå¯ç”¨ï¼Œè¯·è®¾ç½® AI_ENABLED=true")
        return
    
    print("è¯·é€‰æ‹©æµ‹è¯•:")
    print("1. çŸ­æ–‡æœ¬ï¼ˆ5000å­—ç¬¦ï¼‰- ç›´æ¥åˆ†æ")
    print("2. ä¸­é•¿æ–‡æœ¬ï¼ˆ15000å­—ç¬¦ï¼‰- åˆ†æ®µåˆ†æ")
    print("3. è¶…é•¿æ–‡æœ¬ï¼ˆ30000å­—ç¬¦ï¼‰- åˆ†æ®µåˆ†æ")
    print("4. åˆ†æ®µç®—æ³•æµ‹è¯•")
    print("5. ç­–ç•¥å¯¹æ¯”")
    print("6. è¿è¡Œæ‰€æœ‰æµ‹è¯•")
    print()
    
    choice = input("è¯·è¾“å…¥é€‰æ‹© [1-6]: ").strip()
    
    if choice == "1":
        test_short_text()
    elif choice == "2":
        test_medium_text()
    elif choice == "3":
        test_long_text()
    elif choice == "4":
        test_segment_algorithm()
    elif choice == "5":
        compare_strategies()
    elif choice == "6":
        test_short_text()
        test_medium_text()
        test_long_text()
        test_segment_algorithm()
        compare_strategies()
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©")
    
    print("\n" + "="*60)
    print("æµ‹è¯•å®Œæˆï¼")
    print("="*60)


if __name__ == "__main__":
    main()
