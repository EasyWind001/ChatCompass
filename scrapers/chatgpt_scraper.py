"""
ChatGPTåˆ†äº«é“¾æ¥çˆ¬è™«
æ”¯æŒæ ¼å¼: https://chat.openai.com/share/xxx æˆ– https://chatgpt.com/share/xxx
"""
import re
import json
import time
from typing import Optional
from playwright.sync_api import sync_playwright, TimeoutError as PlaywrightTimeout
from bs4 import BeautifulSoup

from .base_scraper import BaseScraper, ConversationData, Message


class ChatGPTScraper(BaseScraper):
    """ChatGPTçˆ¬è™«å®ç°"""
    
    def __init__(self, use_playwright: bool = True):
        super().__init__()
        self.use_playwright = use_playwright
        self.platform_name = 'chatgpt'
    
    def can_handle(self, url: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºChatGPTåˆ†äº«é“¾æ¥"""
        patterns = [
            r'https?://chat\.openai\.com/share/[a-zA-Z0-9\-]+',
            r'https?://chatgpt\.com/share/[a-zA-Z0-9\-]+'
        ]
        return any(re.match(pattern, url) for pattern in patterns)
    
    def scrape(self, url: str) -> ConversationData:
        """æŠ“å–ChatGPTå¯¹è¯å†…å®¹"""
        if not self.validate_url(url):
            raise ValueError(f"æ— æ•ˆçš„URL: {url}")
        
        if not self.can_handle(url):
            raise ValueError(f"ä¸æ”¯æŒçš„ChatGPTé“¾æ¥æ ¼å¼: {url}")
        
        # ä¼˜å…ˆä½¿ç”¨Playwrightï¼ˆå¤„ç†åŠ¨æ€å†…å®¹ï¼‰
        if self.use_playwright:
            return self._scrape_with_playwright(url)
        else:
            return self._scrape_with_requests(url)
    
    def _scrape_with_playwright(self, url: str) -> ConversationData:
        """ä½¿ç”¨PlaywrightæŠ“å–ï¼ˆæ¨èæ–¹å¼ï¼‰"""
        print(f"[ChatGPT] ğŸŒ ä½¿ç”¨PlaywrightæŠ“å–: {url}")
        print(f"[ChatGPT] â³ æ­£åœ¨å¯åŠ¨æµè§ˆå™¨...")
        
        with sync_playwright() as p:
            # å¯åŠ¨æµè§ˆå™¨ï¼ˆæ— å¤´æ¨¡å¼ï¼‰
            browser = p.chromium.launch(headless=True)
            context = browser.new_context(
                user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            )
            page = context.new_page()
            
            try:
                # è®¿é—®é¡µé¢
                print(f"[ChatGPT] ğŸ“¡ æ­£åœ¨åŠ è½½é¡µé¢...")
                page.goto(url, wait_until='networkidle', timeout=30000)
                
                # å°è¯•å¤šç§é€‰æ‹©å™¨ç­‰å¾…å†…å®¹åŠ è½½
                print(f"[ChatGPT] â³ ç­‰å¾…å†…å®¹åŠ è½½...")
                selectors_to_try = [
                    '[data-testid^="conversation-turn"]',
                    'article',
                    '[role="article"]',
                    '[data-message-author-role]',
                    '[class*="conversation"]',
                ]
                
                content_loaded = False
                for selector in selectors_to_try:
                    try:
                        page.wait_for_selector(selector, timeout=10000)
                        print(f"[ChatGPT] å†…å®¹åŠ è½½å®Œæˆ (é€‰æ‹©å™¨: {selector})")
                        content_loaded = True
                        break
                    except PlaywrightTimeout:
                        continue
                
                if not content_loaded:
                    print("[ChatGPT] è­¦å‘Š: ä½¿ç”¨æ ‡å‡†é€‰æ‹©å™¨æœªæ‰¾åˆ°å†…å®¹ï¼Œå°è¯•é€šç”¨æ–¹æ³•...")
                
                # é¢å¤–ç­‰å¾…ç¡®ä¿å†…å®¹å®Œå…¨åŠ è½½
                time.sleep(3)
                
                # è·å–é¡µé¢HTML
                html_content = page.content()
                
                # è§£æå†…å®¹
                soup = BeautifulSoup(html_content, 'html.parser')
                
                # æå–æ ‡é¢˜
                title = self._extract_title(soup, page)
                
                # æå–æ¶ˆæ¯ï¼ˆå°è¯•å¤šç§æ–¹æ³•ï¼‰
                print(f"[ChatGPT] ğŸ” æ­£åœ¨æå–å¯¹è¯å†…å®¹...")
                messages = self._extract_messages_enhanced(soup, page)
                
                if not messages:
                    raise ValueError("æœªèƒ½æå–åˆ°å¯¹è¯å†…å®¹ï¼Œå¯èƒ½é¡µé¢ç»“æ„å·²å˜åŒ–ã€‚è¯·è¿è¡Œ debug_chatgpt.py è¯Šæ–­é—®é¢˜ã€‚")
                
                total_chars = sum(len(msg.content) for msg in messages)
                print(f"[ChatGPT] âœ… æˆåŠŸæå– {len(messages)} æ¡æ¶ˆæ¯ï¼ˆå…± {total_chars:,} å­—ç¬¦ï¼‰")
                
                return ConversationData(
                    platform=self.platform_name,
                    url=url,
                    title=title,
                    messages=messages,
                    metadata={'scrape_method': 'playwright'}
                )
                
            except PlaywrightTimeout:
                raise TimeoutError(f"é¡µé¢åŠ è½½è¶…æ—¶: {url}")
            except Exception as e:
                raise RuntimeError(f"æŠ“å–å¤±è´¥: {str(e)}")
            finally:
                browser.close()
    
    def _scrape_with_requests(self, url: str) -> ConversationData:
        """ä½¿ç”¨requestsæŠ“å–ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼Œå¯èƒ½å¤±è´¥ï¼‰"""
        import requests
        
        print(f"[ChatGPT] ä½¿ç”¨requestsæŠ“å–: {url}")
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        }
        
        try:
            response = requests.get(url, headers=headers, timeout=15)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # å°è¯•ä»<script>æ ‡ç­¾ä¸­æå–JSONæ•°æ®
            script_tags = soup.find_all('script', type='application/json')
            for script in script_tags:
                try:
                    data = json.loads(script.string)
                    # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…JSONç»“æ„è§£æ
                    # ChatGPTçš„åˆ†äº«é¡µé¢å¯èƒ½åœ¨__NEXT_DATA__ä¸­åŒ…å«å¯¹è¯æ•°æ®
                    if 'props' in data and 'pageProps' in data['props']:
                        # è§£æé€»è¾‘ï¼ˆéœ€è¦æ ¹æ®å®é™…ç»“æ„è°ƒæ•´ï¼‰
                        pass
                except:
                    continue
            
            # å¦‚æœJSONè§£æå¤±è´¥ï¼Œå°è¯•HTMLè§£æ
            title = self._extract_title(soup)
            messages = self._extract_messages(soup)
            
            if not messages:
                raise ValueError("requestsæ–¹æ³•æœªèƒ½æå–å†…å®¹ï¼Œå»ºè®®ä½¿ç”¨Playwright")
            
            return ConversationData(
                platform=self.platform_name,
                url=url,
                title=title,
                messages=messages,
                metadata={'scrape_method': 'requests'}
            )
            
        except requests.RequestException as e:
            raise RuntimeError(f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}")
    
    def _extract_title(self, soup: BeautifulSoup, page=None) -> str:
        """æå–å¯¹è¯æ ‡é¢˜"""
        # æ–¹æ³•1: ä»é¡µé¢æ ‡é¢˜æå–
        title_tag = soup.find('title')
        if title_tag and title_tag.string:
            title = title_tag.string.strip()
            # ç§»é™¤"ChatGPT"ç­‰åç¼€
            title = re.sub(r'\s*[-|]\s*ChatGPT.*$', '', title)
            if title and title != 'ChatGPT':
                return title
        
        # æ–¹æ³•2: ä»ç¬¬ä¸€æ¡ç”¨æˆ·æ¶ˆæ¯æå–ï¼ˆæˆªå–å‰50å­—ç¬¦ï¼‰
        first_message = soup.find('[data-testid^="conversation-turn-"]')
        if first_message:
            text = first_message.get_text(strip=True)
            return text[:50] + ('...' if len(text) > 50 else '')
        
        # æ–¹æ³•3: ä½¿ç”¨Playwrightè·å–
        if page:
            try:
                title_element = page.query_selector('h1, [role="heading"]')
                if title_element:
                    return title_element.inner_text()
            except:
                pass
        
        return "æœªå‘½åå¯¹è¯"
    
    def _extract_messages(self, soup: BeautifulSoup) -> list[Message]:
        """æå–å¯¹è¯æ¶ˆæ¯"""
        messages = []
        
        # ChatGPTçš„æ¶ˆæ¯é€šå¸¸åœ¨data-testid="conversation-turn-*"çš„divä¸­
        conversation_turns = soup.find_all('div', {'data-testid': re.compile(r'conversation-turn-\d+')})
        
        for turn in conversation_turns:
            # åˆ¤æ–­è§’è‰²ï¼ˆé€šå¸¸é€šè¿‡classæˆ–dataå±æ€§ï¼‰
            role = self._determine_role(turn)
            
            # æå–æ–‡æœ¬å†…å®¹
            content = self._extract_message_content(turn)
            
            if content:
                messages.append(Message(
                    role=role,
                    content=content.strip()
                ))
        
        return messages
    
    def _extract_messages_enhanced(self, soup: BeautifulSoup, page=None) -> list[Message]:
        """å¢å¼ºçš„æ¶ˆæ¯æå–æ–¹æ³•ï¼ˆæ”¯æŒå¤šç§é¡µé¢ç»“æ„ï¼‰"""
        messages = []
        
        # æ–¹æ³•1: ä½¿ç”¨data-testid
        conversation_turns = soup.find_all('div', {'data-testid': re.compile(r'conversation-turn-\d+')})
        if conversation_turns:
            print(f"[ChatGPT] æ–¹æ³•1: æ‰¾åˆ° {len(conversation_turns)} ä¸ªconversation-turn")
            for turn in conversation_turns:
                role = self._determine_role(turn)
                content = self._extract_message_content(turn)
                if content:
                    messages.append(Message(role=role, content=content.strip()))
            if messages:
                return messages
        
        # æ–¹æ³•2: ä½¿ç”¨articleæ ‡ç­¾
        articles = soup.find_all('article')
        if articles:
            print(f"[ChatGPT] æ–¹æ³•2: æ‰¾åˆ° {len(articles)} ä¸ªarticle")
            for i, article in enumerate(articles):
                # äº¤æ›¿user/assistant
                role = 'user' if i % 2 == 0 else 'assistant'
                content = self._extract_message_content(article)
                if content:
                    messages.append(Message(role=role, content=content.strip()))
            if messages:
                return messages
        
        # æ–¹æ³•3: ä½¿ç”¨data-message-author-role
        message_elements = soup.find_all(attrs={'data-message-author-role': True})
        if message_elements:
            print(f"[ChatGPT] æ–¹æ³•3: æ‰¾åˆ° {len(message_elements)} ä¸ªå¸¦author-roleçš„å…ƒç´ ")
            for element in message_elements:
                role = element.get('data-message-author-role')
                role = 'user' if role == 'user' else 'assistant'
                content = self._extract_message_content(element)
                if content:
                    messages.append(Message(role=role, content=content.strip()))
            if messages:
                return messages
        
        # æ–¹æ³•4: ä½¿ç”¨Playwrightç›´æ¥æå–
        if page:
            print("[ChatGPT] æ–¹æ³•4: å°è¯•ä½¿ç”¨Playwrightç›´æ¥æå–")
            try:
                # å°è¯•æ‰¾åˆ°æ‰€æœ‰æ¶ˆæ¯å…ƒç´ 
                elements = page.query_selector_all('article, [data-testid^="conversation-turn"], [role="article"]')
                if elements:
                    print(f"[ChatGPT] Playwrightæ‰¾åˆ° {len(elements)} ä¸ªæ¶ˆæ¯å…ƒç´ ")
                    for i, element in enumerate(elements):
                        try:
                            text = element.inner_text()
                            if text and len(text.strip()) > 0:
                                role = 'user' if i % 2 == 0 else 'assistant'
                                messages.append(Message(role=role, content=text.strip()))
                        except:
                            continue
                    if messages:
                        return messages
            except Exception as e:
                print(f"[ChatGPT] Playwrightæå–å¤±è´¥: {e}")
        
        # æ–¹æ³•5: é€šç”¨æ–¹æ³• - æŸ¥æ‰¾åŒ…å«å¤§é‡æ–‡æœ¬çš„div
        print("[ChatGPT] æ–¹æ³•5: ä½¿ç”¨é€šç”¨æ–‡æœ¬æå–")
        all_divs = soup.find_all('div', class_=True)
        text_blocks = []
        for div in all_divs:
            text = div.get_text(strip=True)
            # è¿‡æ»¤æ‰å¤ªçŸ­çš„å†…å®¹
            if len(text) > 20 and len(text) < 5000:
                # æ£€æŸ¥æ˜¯å¦æ˜¯ç‹¬ç«‹çš„æ–‡æœ¬å—
                children_text = sum(len(child.get_text(strip=True)) for child in div.find_all('div'))
                if children_text < len(text) * 0.5:  # å­å…ƒç´ æ–‡æœ¬ä¸è¶…è¿‡è‡ªèº«çš„50%
                    text_blocks.append(text)
        
        if text_blocks:
            print(f"[ChatGPT] æ‰¾åˆ° {len(text_blocks)} ä¸ªæ–‡æœ¬å—")
            for i, text in enumerate(text_blocks[:20]):  # æœ€å¤š20æ¡
                role = 'user' if i % 2 == 0 else 'assistant'
                messages.append(Message(role=role, content=text))
            if messages:
                return messages
        
        return messages
    
    def _determine_role(self, element) -> str:
        """åˆ¤æ–­æ¶ˆæ¯è§’è‰²"""
        # æ–¹æ³•1: æ£€æŸ¥data-message-author-roleå±æ€§
        author_role = element.get('data-message-author-role')
        if author_role:
            return 'user' if author_role == 'user' else 'assistant'
        
        # æ–¹æ³•2: æ£€æŸ¥classåç§°
        classes = element.get('class', [])
        class_str = ' '.join(classes) if isinstance(classes, list) else classes
        
        if 'user' in class_str.lower():
            return 'user'
        elif 'assistant' in class_str.lower() or 'bot' in class_str.lower():
            return 'assistant'
        
        # æ–¹æ³•3: æ£€æŸ¥å­å…ƒç´ 
        if element.find('div', class_=re.compile(r'.*agent.*', re.I)):
            return 'assistant'
        
        # é»˜è®¤äº¤æ›¿åˆ¤æ–­ï¼ˆç¬¬ä¸€æ¡é€šå¸¸æ˜¯userï¼‰
        return 'user'
    
    def _extract_message_content(self, element) -> str:
        """æå–æ¶ˆæ¯æ–‡æœ¬å†…å®¹"""
        # ç§»é™¤ä¸éœ€è¦çš„å…ƒç´ ï¼ˆæŒ‰é’®ã€å›¾æ ‡ç­‰ï¼‰
        for unwanted in element.find_all(['button', 'svg', 'img']):
            unwanted.decompose()
        
        # è·å–çº¯æ–‡æœ¬
        text = element.get_text(separator='\n', strip=True)
        
        # æ¸…ç†å¤šä½™ç©ºç™½
        text = re.sub(r'\n{3,}', '\n\n', text)
        
        return text


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == '__main__':
    scraper = ChatGPTScraper(use_playwright=True)
    
    # æµ‹è¯•URL
    test_url = "https://chatgpt.com/share/example-id"
    
    if scraper.can_handle(test_url):
        try:
            data = scraper.scrape(test_url)
            print(f"æ ‡é¢˜: {data.title}")
            print(f"æ¶ˆæ¯æ•°: {data.message_count}")
            print(f"å­—æ•°: {data.word_count}")
            print("\nå®Œæ•´å¯¹è¯:")
            print(data.get_full_text())
        except Exception as e:
            print(f"é”™è¯¯: {e}")
