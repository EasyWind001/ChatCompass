"""
å¤§æ–‡æœ¬å¤„ç†æµ‹è¯•ç¤ºä¾‹

æ¼”ç¤ºChatCompasså¦‚ä½•å¤„ç†è¶…é•¿å¯¹è¯æ–‡æœ¬
"""
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from ai import get_ai_service, AIConfig
import logging

# é…ç½®æ—¥å¿—æ˜¾ç¤ºè¯¦ç»†è¿›åº¦
logging.basicConfig(
    level=logging.INFO,
    format='%(message)s'
)


def generate_large_conversation(size: str = "small") -> str:
    """ç”Ÿæˆæµ‹è¯•ç”¨çš„å¤§æ–‡æœ¬å¯¹è¯"""
    
    base_conversation = """
ç”¨æˆ·: ä½ å¥½ï¼Œæˆ‘æƒ³å­¦ä¹ Dockeréƒ¨ç½²åº”ç”¨ï¼Œåº”è¯¥ä»å“ªé‡Œå¼€å§‹ï¼Ÿ

åŠ©æ‰‹: Dockeræ˜¯å®¹å™¨åŒ–æŠ€æœ¯çš„ä»£è¡¨ï¼Œå­¦ä¹ Dockeréƒ¨ç½²éœ€è¦æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤ï¼š

1. **ç†è§£å®¹å™¨æ¦‚å¿µ**
   - å®¹å™¨ vs è™šæ‹Ÿæœº
   - é•œåƒå’Œå®¹å™¨çš„åŒºåˆ«
   - Dockeræ¶æ„

2. **å®‰è£…Docker**
   - Windows: Docker Desktop
   - Linux: docker-engine
   - MacOS: Docker Desktop

3. **åŸºç¡€å‘½ä»¤**
   - docker run: è¿è¡Œå®¹å™¨
   - docker build: æ„å»ºé•œåƒ
   - docker-compose: å¤šå®¹å™¨ç¼–æ’

4. **ç¼–å†™Dockerfile**
   ```dockerfile
   FROM python:3.9
   WORKDIR /app
   COPY . .
   RUN pip install -r requirements.txt
   CMD ["python", "main.py"]
   ```

5. **ä½¿ç”¨docker-compose**
   ```yaml
   version: '3'
   services:
     app:
       build: .
       ports:
         - "5000:5000"
     db:
       image: postgres:13
   ```

ç”¨æˆ·: å¦‚ä½•ä¼˜åŒ–Dockeré•œåƒå¤§å°ï¼Ÿ

åŠ©æ‰‹: ä¼˜åŒ–Dockeré•œåƒå¤§å°çš„æœ€ä½³å®è·µï¼š

1. **ä½¿ç”¨AlpineåŸºç¡€é•œåƒ**
   ```dockerfile
   FROM python:3.9-alpine  # æ¯”æ ‡å‡†é•œåƒå°10å€
   ```

2. **å¤šé˜¶æ®µæ„å»º**
   ```dockerfile
   # æ„å»ºé˜¶æ®µ
   FROM node:16 AS builder
   COPY . .
   RUN npm run build
   
   # è¿è¡Œé˜¶æ®µ
   FROM nginx:alpine
   COPY --from=builder /app/dist /usr/share/nginx/html
   ```

3. **åˆå¹¶RUNå‘½ä»¤**
   ```dockerfile
   # âŒ ä¸å¥½
   RUN apt-get update
   RUN apt-get install -y git
   RUN apt-get clean
   
   # âœ… å¥½
   RUN apt-get update && \\
       apt-get install -y git && \\
       apt-get clean && \\
       rm -rf /var/lib/apt/lists/*
   ```

4. **ä½¿ç”¨.dockerignore**
   ```
   node_modules/
   .git/
   *.log
   __pycache__/
   ```

5. **æ¸…ç†ç¼“å­˜**
   ```dockerfile
   RUN pip install --no-cache-dir -r requirements.txt
   ```

ç”¨æˆ·: Docker Composeå¦‚ä½•ç®¡ç†å¤šä¸ªç¯å¢ƒï¼Ÿ

åŠ©æ‰‹: ç®¡ç†å¤šç¯å¢ƒçš„å‡ ç§æ–¹æ¡ˆï¼š

1. **ä½¿ç”¨å¤šä¸ªcomposeæ–‡ä»¶**
   ```bash
   # docker-compose.yml (åŸºç¡€é…ç½®)
   # docker-compose.dev.yml (å¼€å‘ç¯å¢ƒ)
   # docker-compose.prod.yml (ç”Ÿäº§ç¯å¢ƒ)
   
   # å¼€å‘ç¯å¢ƒ
   docker-compose -f docker-compose.yml -f docker-compose.dev.yml up
   
   # ç”Ÿäº§ç¯å¢ƒ
   docker-compose -f docker-compose.yml -f docker-compose.prod.yml up
   ```

2. **ä½¿ç”¨ç¯å¢ƒå˜é‡**
   ```yaml
   services:
     app:
       image: myapp:${TAG:-latest}
       environment:
         - ENV=${ENV:-production}
   ```

3. **ä½¿ç”¨.envæ–‡ä»¶**
   ```bash
   # .env.dev
   TAG=dev
   DATABASE_URL=postgresql://localhost:5432/dev_db
   
   # .env.prod
   TAG=latest
   DATABASE_URL=postgresql://prod-server:5432/prod_db
   ```

"""
    
    if size == "small":
        return base_conversation
    
    elif size == "medium":
        # å¤åˆ¶3æ¬¡ï¼Œæ¨¡æ‹Ÿä¸­ç­‰é•¿åº¦
        return base_conversation * 3
    
    elif size == "large":
        # å¤åˆ¶10æ¬¡ï¼Œæ¨¡æ‹Ÿå¤§æ–‡æœ¬ï¼ˆçº¦1.5ä¸‡å­—ç¬¦ï¼‰
        return base_conversation * 10
    
    elif size == "huge":
        # å¤åˆ¶30æ¬¡ï¼Œæ¨¡æ‹Ÿè¶…å¤§æ–‡æœ¬ï¼ˆçº¦4.5ä¸‡å­—ç¬¦ï¼‰
        return base_conversation * 30
    
    return base_conversation


def test_small_text():
    """æµ‹è¯•å°æ–‡æœ¬ï¼ˆæ­£å¸¸é€Ÿåº¦ï¼‰"""
    print("\n" + "="*70)
    print("æµ‹è¯•1: å°æ–‡æœ¬å¤„ç†ï¼ˆçº¦1500å­—ç¬¦ï¼‰")
    print("="*70 + "\n")
    
    ai_service = get_ai_service()
    
    if not ai_service.is_available():
        print("âŒ AIæœåŠ¡ä¸å¯ç”¨ï¼Œè¯·ç¡®ä¿Ollamaå·²å¯åŠ¨")
        return
    
    conversation = generate_large_conversation("small")
    print(f"ğŸ“„ æ–‡æœ¬é•¿åº¦: {len(conversation):,} å­—ç¬¦\n")
    
    result = ai_service.analyze_conversation(
        conversation,
        title="Dockeréƒ¨ç½²å…¥é—¨",
        show_progress=True
    )
    
    if result:
        print(f"\nâœ… åˆ†ææˆåŠŸ!")
        print(f"ğŸ“ æ‘˜è¦: {result.summary[:100]}...")
        print(f"ğŸ“ åˆ†ç±»: {result.category}")
        print(f"ğŸ·ï¸  æ ‡ç­¾: {', '.join(result.tags)}")


def test_large_text():
    """æµ‹è¯•å¤§æ–‡æœ¬ï¼ˆè§¦å‘æ™ºèƒ½æˆªæ–­ï¼‰"""
    print("\n" + "="*70)
    print("æµ‹è¯•2: å¤§æ–‡æœ¬å¤„ç†ï¼ˆçº¦15,000å­—ç¬¦ï¼Œè§¦å‘æ™ºèƒ½æˆªæ–­ï¼‰")
    print("="*70 + "\n")
    
    ai_service = get_ai_service()
    
    if not ai_service.is_available():
        print("âŒ AIæœåŠ¡ä¸å¯ç”¨ï¼Œè¯·ç¡®ä¿Ollamaå·²å¯åŠ¨")
        return
    
    conversation = generate_large_conversation("large")
    print(f"ğŸ“„ æ–‡æœ¬é•¿åº¦: {len(conversation):,} å­—ç¬¦")
    print(f"ğŸ’¡ å°†è§¦å‘æ™ºèƒ½æˆªæ–­ä¼˜åŒ–\n")
    
    result = ai_service.analyze_conversation(
        conversation,
        title="Dockeréƒ¨ç½²å®Œæ•´æ•™ç¨‹",
        show_progress=True
    )
    
    if result:
        print(f"\nâœ… åˆ†ææˆåŠŸ!")
        print(f"ğŸ“ æ‘˜è¦: {result.summary[:100]}...")
        print(f"ğŸ“ åˆ†ç±»: {result.category}")
        print(f"ğŸ·ï¸  æ ‡ç­¾: {', '.join(result.tags)}")


def test_huge_text():
    """æµ‹è¯•è¶…å¤§æ–‡æœ¬ï¼ˆæ¨¡æ‹ŸçœŸå®åœºæ™¯ï¼‰"""
    print("\n" + "="*70)
    print("æµ‹è¯•3: è¶…å¤§æ–‡æœ¬å¤„ç†ï¼ˆçº¦45,000å­—ç¬¦ï¼Œæ¥è¿‘çœŸå®åœºæ™¯ï¼‰")
    print("="*70 + "\n")
    
    ai_service = get_ai_service()
    
    if not ai_service.is_available():
        print("âŒ AIæœåŠ¡ä¸å¯ç”¨ï¼Œè¯·ç¡®ä¿Ollamaå·²å¯åŠ¨")
        return
    
    conversation = generate_large_conversation("huge")
    print(f"ğŸ“„ æ–‡æœ¬é•¿åº¦: {len(conversation):,} å­—ç¬¦")
    print(f"ğŸ’¡ å°†è§¦å‘æ™ºèƒ½æˆªæ–­ + æµå¼è¾“å‡º\n")
    
    result = ai_service.analyze_conversation(
        conversation,
        title="Dockerå®Œæ•´çŸ¥è¯†ä½“ç³»",
        show_progress=True
    )
    
    if result:
        print(f"\nâœ… åˆ†ææˆåŠŸ!")
        print(f"ğŸ“ æ‘˜è¦: {result.summary[:100]}...")
        print(f"ğŸ“ åˆ†ç±»: {result.category}")
        print(f"ğŸ·ï¸  æ ‡ç­¾: {', '.join(result.tags)}")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("\n" + "="*70)
    print("ChatCompass å¤§æ–‡æœ¬å¤„ç†æµ‹è¯•")
    print("="*70)
    print("\næœ¬æµ‹è¯•å°†æ¼”ç¤ºä»¥ä¸‹ä¼˜åŒ–åŠŸèƒ½ï¼š")
    print("1. âœ… æ™ºèƒ½æˆªæ–­ï¼ˆä¿ç•™å¼€å¤´70% + ç»“å°¾30%ï¼‰")
    print("2. âœ… å®æ—¶è¿›åº¦æç¤º")
    print("3. âœ… å¤„ç†æ—¶é—´é¢„ä¼°")
    print("4. âœ… æµå¼è¾“å‡ºï¼ˆå¤§æ–‡æœ¬ï¼‰")
    print("\nè¯·ç¡®ä¿ï¼š")
    print("- OllamaæœåŠ¡å·²å¯åŠ¨ (ollama serve)")
    print("- å·²æ‹‰å–æ¨¡å‹ (ollama pull qwen2.5:3b)")
    
    input("\næŒ‰Enterå¼€å§‹æµ‹è¯•...")
    
    # è¿è¡Œæµ‹è¯•
    try:
        test_small_text()
        input("\næŒ‰Enterç»§ç»­ä¸‹ä¸€ä¸ªæµ‹è¯•...")
        
        test_large_text()
        input("\næŒ‰Enterç»§ç»­æœ€åä¸€ä¸ªæµ‹è¯•...")
        
        test_huge_text()
        
        print("\n" + "="*70)
        print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
        print("="*70)
        print("\næ€»ç»“ï¼š")
        print("- å°æ–‡æœ¬ï¼šæ­£å¸¸é€Ÿåº¦ï¼Œæ— ä¼˜åŒ–")
        print("- å¤§æ–‡æœ¬ï¼šæ™ºèƒ½æˆªæ–­ï¼Œé€Ÿåº¦æå‡2-3å€")
        print("- è¶…å¤§æ–‡æœ¬ï¼šæ™ºèƒ½æˆªæ–­ + æµå¼è¾“å‡ºï¼Œç”¨æˆ·ä½“éªŒæœ€ä½³")
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  æµ‹è¯•è¢«ä¸­æ–­")
    except Exception as e:
        print(f"\n\nâŒ æµ‹è¯•å¤±è´¥: {e}")


if __name__ == '__main__':
    main()
